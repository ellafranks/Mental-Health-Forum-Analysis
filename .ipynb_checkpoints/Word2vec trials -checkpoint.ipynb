{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec: Uses pre trained model with over 100 billion words \n",
    "\n",
    "- Pros: Vast corpus of language that captures word meanings in a statistically robust manner.\n",
    "- Cons: May not capture the peculiarities of language in my specific application domain.\n",
    "\n",
    "\n",
    "- Similarity of words are measured by using the cosine distance between two different word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:57:09.246726Z",
     "start_time": "2020-03-01T14:57:01.478301Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import emoji \n",
    "import re\n",
    "from emoji import emojize\n",
    "from emoji import *\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:59:43.990136Z",
     "start_time": "2020-03-01T14:57:09.306178Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Prepare dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:59:50.574346Z",
     "start_time": "2020-03-01T14:59:44.056823Z"
    }
   },
   "outputs": [],
   "source": [
    "sw = pd.read_csv('../Datasets_capstone/sw_final.csv', encoding='utf8', engine='python')\n",
    "del sw['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:59:50.763285Z",
     "start_time": "2020-03-01T14:59:50.580737Z"
    }
   },
   "outputs": [],
   "source": [
    "sw.drop_duplicates('comment_body', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:59:51.059571Z",
     "start_time": "2020-03-01T14:59:50.828244Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove emojis \n",
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "sw.comment_body = sw.comment_body.apply(lambda x: deEmojify(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:59:51.069991Z",
     "start_time": "2020-03-01T14:59:51.064306Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = sw.comment_body.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:59:51.365140Z",
     "start_time": "2020-03-01T14:59:51.074436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning data - remove punctuation from every newsgroup text\n",
    "sentences = []\n",
    "# Go through each text in turn\n",
    "for ii in range(len(texts)):\n",
    "    sentences = [re.sub(pattern=r'[\\!\"#$%&\\*+,-./:;<=>?@^_`()|~=]', \n",
    "                        repl='', \n",
    "                        string=x\n",
    "                       ).strip().split(' ') for x in texts[ii].split('\\n') \n",
    "                      if not x.endswith('writes:')]\n",
    "    sentences = [x for x in sentences if x != ['']]\n",
    "    texts[ii] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:59:51.376323Z",
     "start_time": "2020-03-01T14:59:51.368167Z"
    }
   },
   "outputs": [],
   "source": [
    "# concatenate all sentences from all texts into a single list of sentences\n",
    "all_sentences = []\n",
    "for text in texts:\n",
    "    all_sentences += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T14:59:51.396738Z",
     "start_time": "2020-03-01T14:59:51.380078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16275"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T15:10:33.241877Z",
     "start_time": "2020-03-01T15:09:05.328643Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(all_sentences, \n",
    "                 min_count=3,   # Ignore words that appear less than this\n",
    "                 size=1000,      # Dimensionality of word embeddings\n",
    "                 workers=2,     # Number of processors (parallelisation)\n",
    "                 window=5,      # Context window for words during training\n",
    "                 iter=30)       # Number of epochs training over corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T15:10:33.263711Z",
     "start_time": "2020-03-01T15:10:33.252285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T15:10:33.281478Z",
     "start_time": "2020-03-01T15:10:33.276370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9400"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-01T15:10:33.373643Z",
     "start_time": "2020-03-01T15:10:33.285954Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellafranks/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('hello', 0.5232001543045044),\n",
       " ('wow', 0.5138623714447021),\n",
       " ('wtf', 0.4823949337005615),\n",
       " ('k', 0.46533775329589844),\n",
       " (\"C'mon\", 0.4614157974720001),\n",
       " ('Omg', 0.4549916088581085),\n",
       " ('oh', 0.4526345729827881),\n",
       " ('Jesus', 0.4490479528903961),\n",
       " ('hey', 0.445531964302063),\n",
       " ('Wait', 0.43569186329841614)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
